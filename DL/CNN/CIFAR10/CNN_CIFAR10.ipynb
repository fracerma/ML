{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_CIFAR10.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "MArwg9PGuCg_",
        "th_PzX6bhkgK",
        "-KlcYe9wY6Qp",
        "ufVJHsxQY7bV",
        "8xUqoC8KfF-1",
        "DPg20xrbfkzI",
        "zX8SmMKGieWa"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to drive"
      ],
      "metadata": {
        "id": "MArwg9PGuCg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "8kaRJwlTuFk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /gdrive/My Drive/AI/CNN/CIFAR10"
      ],
      "metadata": {
        "id": "wJ5O5RobuMOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "th_PzX6bhkgK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2RFS8ImYAjt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and import visualkeras library\n",
        "!pip install visualkeras\n",
        "import visualkeras"
      ],
      "metadata": {
        "id": "mqigmnm7iE3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kLPIcsM9t_ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set seed"
      ],
      "metadata": {
        "id": "-KlcYe9wY6Qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)"
      ],
      "metadata": {
        "id": "VR3A3x92Yc9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data\n",
        "\n",
        "CIFAR10 dataset"
      ],
      "metadata": {
        "id": "ufVJHsxQY7bV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dataset and plit it\n",
        "(X_train_val , y_train_val) , (X_test, y_test) = tfk.datasets.cifar10.load_data()\n",
        "labels = {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer', 5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}\n",
        "X_train_val.shape"
      ],
      "metadata": {
        "id": "Mw1WnGGdY5II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect the data"
      ],
      "metadata": {
        "id": "8xUqoC8KfF-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_row = 2\n",
        "num_col = 5\n",
        "fig, axes = plt.subplots(num_row, num_col, figsize=(10*num_row,2*num_col))\n",
        "for i in range(num_row*num_col):\n",
        "    ax = axes[i//num_col, i%num_col]\n",
        "    ax.imshow(X_train_val[i])\n",
        "    ax.set_title('{}'.format(labels[y_train_val[i][0]]))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jUD1b1h6fIxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing data"
      ],
      "metadata": {
        "id": "DPg20xrbfkzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization\n",
        "\n",
        "X_train_val = X_train_val / 255.\n",
        "X_test = X_test / 255.\n",
        "\n",
        "# Labels to categorical (one hot)\n",
        "y_train_val = tfk.utils.to_categorical(y_train_val)\n",
        "y_test = tfk.utils.to_categorical(y_test)\n",
        "\n",
        "# Split validation and train\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, random_state=seed, test_size = 0.1, stratify=y_train_val)"
      ],
      "metadata": {
        "id": "svZtImCngGHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models metadata"
      ],
      "metadata": {
        "id": "zX8SmMKGieWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "batch_size = 128\n",
        "epochs = 200"
      ],
      "metadata": {
        "id": "zkkVmOB4iiJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Model"
      ],
      "metadata": {
        "id": "r6ian0Ubimok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape):\n",
        "  input_layer = tfkl.Input(shape=input_shape, name=\"InputLayer\")\n",
        "  # CNN part\n",
        "  conv1 = tfkl.Conv2D(\n",
        "      filters=8,\n",
        "      kernel_size=(3, 3),\n",
        "      strides = (1, 1),\n",
        "      padding = 'same',\n",
        "      activation = 'relu',\n",
        "      kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "  )(input_layer)\n",
        "  conv2 = tfkl.Conv2D(\n",
        "      filters=16,\n",
        "      kernel_size=(3, 3),\n",
        "      strides = (1, 1),\n",
        "      padding = 'same',\n",
        "      activation = 'relu',\n",
        "      kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "  )(conv1)\n",
        "  pool1 = tfkl.MaxPooling2D(\n",
        "      pool_size = (2, 2)\n",
        "  )(conv2)\n",
        "\n",
        "  conv3 = tfkl.Conv2D(\n",
        "      filters=32,\n",
        "      kernel_size=(3, 3),\n",
        "      strides = (1, 1),\n",
        "      padding = 'same',\n",
        "      activation = 'relu',\n",
        "      kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "  )(pool1)\n",
        "  conv4 = tfkl.Conv2D(\n",
        "      filters=64,\n",
        "      kernel_size=(3, 3),\n",
        "      strides = (1, 1),\n",
        "      padding = 'same',\n",
        "      activation = 'relu',\n",
        "      kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "  )(conv3)\n",
        "  pool2 = tfkl.MaxPooling2D(\n",
        "      pool_size = (2, 2)\n",
        "  )(conv4)\n",
        "\n",
        "  conv5 = tfkl.Conv2D(\n",
        "      filters=128,\n",
        "      kernel_size=(3, 3),\n",
        "      strides = (1, 1),\n",
        "      padding = 'same',\n",
        "      activation = 'relu',\n",
        "      kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "  )(pool2)\n",
        "  pool3 = tfkl.MaxPooling2D(\n",
        "      pool_size = (2, 2)\n",
        "  )(conv5)\n",
        "\n",
        "  # FC part\n",
        "  flattening_layer = tfkl.Flatten()(pool3)\n",
        "  flattening_layer = tfkl.Dropout(0.3,seed=seed)(flattening_layer)\n",
        "  classifier_layer = tfkl.Dense(units = 256, activation='relu')(flattening_layer)\n",
        "  classifier_layer = tfkl.Dropout(0.2,seed=seed)(classifier_layer)\n",
        "  hidden_layer = tfkl.Dense(units = 256, activation='relu')(classifier_layer)\n",
        "  hidden_layer = tfkl.Dropout(0.1,seed=seed)(hidden_layer)\n",
        "  output_layer = tfkl.Dense(units=10, activation='softmax')(hidden_layer)\n",
        "\n",
        "  model = tfk.Model(inputs=input_layer, outputs=output_layer, name='CIFAR_model')\n",
        "\n",
        "  model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "  return model"
      ],
      "metadata": {
        "id": "FjhKt3NbiopT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(input_shape)\n",
        "print(model.summary())\n",
        "visualkeras.layered_view(model, legend=True, spacing=20, scale_xy=10)"
      ],
      "metadata": {
        "id": "uUSRaHuKpyO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "4WRcLYE4rzVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    x = X_train,\n",
        "    y = y_train,\n",
        "    batch_size = batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_data = (X_val, y_val),\n",
        "    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=10, restore_best_weights=True)]\n",
        ").history"
      ],
      "metadata": {
        "id": "uUJXMxkGr1W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(history['loss'], label='Training', alpha=.8, color='#ff7f0e')\n",
        "plt.plot(history['val_loss'], label='Validation', alpha=.8, color='#4D61E2')\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Binary Crossentropy')\n",
        "plt.grid(alpha=.3)\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(history['accuracy'], label='Training', alpha=.8, color='#ff7f0e')\n",
        "plt.plot(history['val_accuracy'], label='Validation', alpha=.8, color='#4D61E2')\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Accuracy')\n",
        "plt.grid(alpha=.3)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m_xgm50hscCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "eZylVrLLzvSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the test set with the CNN\n",
        "predictions = model.predict(X_test)\n",
        "predictions.shape"
      ],
      "metadata": {
        "id": "RvM-GkElzxOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy = accuracy_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "precision = precision_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "recall = recall_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "f1 = f1_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy.round(4))\n",
        "print('Precision:',precision.round(4))\n",
        "print('Recall:',recall.round(4))\n",
        "print('F1:',f1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm.T, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5HWDdQPtz9r7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test with my image"
      ],
      "metadata": {
        "id": "I1YDm9Hmtzua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image = Image.open(\"dog.png\")\n",
        "image_crop = image.resize((32,32),Image.ANTIALIAS)\n",
        "image_arr = np.array(image_crop, dtype=np.float32)[:,:,:3]\n",
        "prediction = model.predict(image_arr[None, ...])\n",
        "prediction[0]"
      ],
      "metadata": {
        "id": "fkfvXY68tzhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the target images and the predictions\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1,2)\n",
        "fig.set_size_inches(15,5)\n",
        "ax1.imshow(image)\n",
        "ax2.barh(list(labels.values()), prediction[0], color=plt.get_cmap('Paired').colors)\n",
        "ax2.set_title('Predicted label: '+labels[np.argmax(prediction[0])])\n",
        "ax2.grid(alpha=.3)\n",
        "plt.show()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uIpGuvKYwRih"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}